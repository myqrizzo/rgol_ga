{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb3d32cf67f12406353cb3550577cd3685e77fe4"},"cell_type":"code","source":"df = pd.read_csv('../input/test.csv', index_col='id', skiprows=range(1, 400))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%load_ext Cython","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a1de9c9fc845912e606ab051d1a9368230412e5"},"cell_type":"code","source":"%%cython \n\ncimport cython\nimport numpy as np\n\n@cython.cdivision(True)\n@cython.boundscheck(False)\n@cython.nonecheck(False)\n@cython.wraparound(False)\ncdef int calc_neighs(unsigned char[:, :] field, int i, int j, int n):\n    cdef:\n        int neighs = 0;\n        int k, row_idx, col_idx;\n    neighs = 0\n    if i - 1 >= 0 and j - 1 >= 0 and field[i - 1, j - 1]:\n        neighs += 1\n    if i - 1 >= 0 and field[i - 1, j]:\n        neighs += 1\n    if i - 1 >= 0 and j + 1 < n and field[i - 1, j + 1]:\n        neighs += 1\n    if j - 1 >= 0 and field[i, j - 1]:\n        neighs += 1\n    if j + 1 < n and field[i, j + 1]:\n        neighs += 1\n    if i + 1 < n and j - 1 >= 0 and field[i + 1, j - 1]:\n        neighs += 1\n    if i + 1 < n and field[i + 1, j]:\n        neighs += 1\n    if i + 1 < n and j + 1 < n and field[i + 1, j + 1]:\n        neighs += 1\n    return neighs\n\n@cython.cdivision(True)\n@cython.boundscheck(False)\n@cython.nonecheck(False)\n@cython.wraparound(False)\ncpdef make_move(unsigned char[:, :] field, int moves):\n    cdef:\n        int _, i, j, neighs;\n        int n;\n        int switch = 0;\n        unsigned char[:, :] cur_field;\n        unsigned char[:, :] next_field;\n    cur_field = np.copy(field)\n    next_field = np.zeros_like(field, 'uint8')\n    n = len(field)\n    for _ in range(moves):\n        if switch == 0:\n            for i in range(n):\n                for j in range(n):\n                    neighs = calc_neighs(cur_field, i, j, n)\n                    if cur_field[i, j] and neighs == 2:\n                        next_field[i, j] = 1\n                    elif neighs == 3:\n                        next_field[i, j] = 1\n                    else:\n                        next_field[i, j] = 0\n        else:\n            for i in range(n):\n                for j in range(n):\n                    neighs = calc_neighs(next_field, i, j, n)\n                    if next_field[i, j] and neighs == 2:\n                        cur_field[i, j] = 1\n                    elif neighs == 3:\n                        cur_field[i, j] = 1\n                    else:\n                        cur_field[i, j] = 0\n        switch = (switch + 1) % 2\n    return np.array(next_field if switch else cur_field)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9083e6768ae28d3a8b0bb9d363d4773b1f3862e6"},"cell_type":"code","source":"import numpy as np\nimport multiprocessing as mp\nfrom functools import partial\n\n      \ndef parallel_fitness(gene, Y, delta):\n    candidate = make_move(gene, moves=delta)\n    return (candidate == Y).sum() / 400\n\nclass GeneticSolver:\n    def __init__(self, population_size=800, n_generations=2000, retain_best=0.8, retain_random=0.05, mutate_chance=0.05,\n                 verbosity=0, verbosity_step=20, random_state=-1, warm_start=False, early_stopping=True, patience=20,\n                 initialization_strategy='uniform', fitness_parallel=False):\n        \"\"\"\n        :param population_size: number of individual candidate solutions\n        :param n_generations: number of generations\n        :param retain_best: percentage of best candidates to select into the next generation\n        :param retain_random: probability of selecting sub-optimal candidate into the next generation\n        :param mutate_chance: candidate mutation chance\n        :param verbosity: level of verbosity (0 - quiet, 1 - evolution information, 2 - spamming like in 2003)\n        :param random_state: if specified, initializes seed with this value\n        :param warm_start: if True, initial population generation step is omitted, allowing for continuing training\n        :param early_stopping: if True, evolution will stop if top-10 candidates are not changing for several generations\n        :param patience: number of generations to wait for best solution change when <early_stopping>\n        :param initialization_strategy: initial population generation rule: 'uniform' or 'covering'\n        \"\"\"\n        self.population_size = population_size\n        self.n_generations = n_generations\n        self.retain_best = retain_best\n        self.retain_random = retain_random\n        self.mutate_chance = mutate_chance\n        self.verbosity = verbosity\n        self.verbosity_step = verbosity_step\n        self.random_state = random_state\n        self.warm_start = warm_start\n        self.early_stopping = early_stopping\n        self.patience = patience\n        self.initialization_strategy = initialization_strategy\n        self.fitness_parallel = fitness_parallel\n        if fitness_parallel:\n            self.pool = mp.Pool(mp.cpu_count())\n        else:\n            self.pool = None\n\n        self._population = None\n        if random_state != -1:\n            np.random.seed(random_state)\n\n    def solve(self, Y, delta, n_generations=-1):\n        \"\"\"\n\n        :param Y: 20x20 array that represents field in stopping condition\n        :param delta: number of steps to revert\n        :param n_generations: number of evolution generations. Overrides initialization value if specified\n        :return: 20x20 array that represents the best start field found and associated fitness value\n        \"\"\"\n        if not (self._population and self.warm_start):\n            self._population = self._generate_population()\n        if n_generations != -1:\n            self.n_generations = n_generations\n        scores = np.zeros(len(self._population))\n        prev_scores = np.zeros(len(self._population))\n        cnt_no_change_in_scores = 0\n        for generation in range(self.n_generations):\n            self._population, scores = self.evolve(Y, delta)\n            if np.isclose(prev_scores[:10], scores[:10]).all():\n                cnt_no_change_in_scores += 1\n            else:\n                cnt_no_change_in_scores = 0\n                prev_scores = scores\n            if self.verbosity and generation % self.verbosity_step == 0:\n                if generation == 0:\n                    print(f\"Generation #: best score\")\n                else:\n                    print(f\"Generation {generation}: {scores[0]}\")\n            if np.isclose(scores[:10], 1).any() or (self.early_stopping and cnt_no_change_in_scores >= self.patience):\n                if self.verbosity:\n                    print(f\"Early stopping on generation {generation} with best score {scores[0]}\")\n                break\n        return self._population[0], scores[0]\n\n    def _generate_population(self):\n        \"\"\"\n        Generating initial population of individual solutions\n\n        Regardless of strategy, we make 5 initial \"warming\" steps to make distribution closer to the problem.\n\n        Strategies description:\n\n            * Uniform: each cell has equal probability of being initialized as alive or dead. This will introduce no\n                       prior information at all\n            * Covering: Each individual is generated with it's own probability of having each cell 'alive'. This gives\n                       on average higher initial fitness score, but has no observed effect on long-term behavior\n        :return: initial population as a list of 20x20 arrays\n        \"\"\"\n        if self.initialization_strategy == 'uniform':\n            initial_states = np.split(np.random.binomial(1, 0.5, (20 * self.population_size, 20)).astype('uint8'), self.population_size)\n            return [make_move(state, 5) for state in initial_states]\n        elif self.initialization_strategy == 'covering':\n            \"\"\" Idea is to cover all the range of possible values for 'density' parameter \"\"\"\n            alive_probabilities = np.linspace(0.01, 0.99, self.population_size)\n            return [make_move(np.random.binomial(1, prob, size=(20, 20)), moves=5) for prob in alive_probabilities]\n        else:\n            raise NotImplementedError(f\"{self.initialization_strategy} is not implemented!\")\n\n    def evolve(self, Y, delta):\n        \"\"\"\n        Evolution step\n        :param Y: 20x20 array that represents field in stopping condition\n        :param delta: number of steps to revert\n        :return: new generation of the same size along with scores of the best retained individuals\n        \"\"\"\n        if self.fitness_parallel:\n          scores = np.array(self.parallel_score_population(self._population, Y, delta))\n        else:\n          scores = np.array(self.score_population(self._population, Y, delta))\n        retain_len = int(len(scores) * self.retain_best)\n        sorted_indices = np.argsort(scores)[::-1]\n        self._population = [self._population[idx] for idx in sorted_indices]\n        best_scores = scores[sorted_indices][:retain_len]\n        if self.verbosity > 1:\n            print(\"best scores:\", best_scores)\n        parents = self._population[:retain_len]\n        leftovers = self._population[retain_len:]\n\n        cnt_degenerate = 0\n        for gene in leftovers:\n            if np.random.rand() < self.retain_random:\n                cnt_degenerate += 1\n                parents.append(gene)\n        if self.verbosity > 1:\n            print(f\"# of degenerates left: {cnt_degenerate}\")\n\n        cnt_mutations = 0\n        for gene in parents[1:]:  # mutate everyone expecting for the best candidate\n            if np.random.rand() < self.mutate_chance:\n                self.mutate(gene)\n                cnt_mutations += 1\n        if self.verbosity > 1:\n            print(f\"# of mutations: {cnt_mutations}\")\n\n        places_left = self.population_size - retain_len\n        children = []\n        while len(children) < places_left:\n            mom_idx, dad_idx = np.random.randint(0, retain_len - 1, 2)\n            if mom_idx != dad_idx:\n                child1, child2 = self.crossover(parents[mom_idx], parents[dad_idx])\n                children.append(child1)\n                if len(children) < places_left:\n                    children.append(child2)\n        if self.verbosity > 1:\n            print(f\"# of children: {len(children)}\")\n        parents.extend(children)\n        return parents, best_scores\n\n    @classmethod\n    def crossover(cls, mom, dad):\n        \"\"\"\n        Take two parents, return two children, interchanging half of the allels of each parent randomly\n        \"\"\"\n        # select_mask = np.random.randint(0, 2, size=(20, 20), dtype='bool')\n        select_mask = np.random.binomial(1, 0.5, size=(20, 20)).astype('bool')\n        child1, child2 = np.copy(mom), np.copy(dad)\n        child1[select_mask] = dad[select_mask]\n        child2[select_mask] = mom[select_mask]\n        return child1, child2\n\n    @classmethod\n    def mutate(cls, field):\n        \"\"\"\n        Inplace mutation of the provided field\n        \"\"\"\n        a = np.random.binomial(1, 0.1, size=(20, 20)).astype('bool')\n        field[a] += 1\n        field[a] %= 2\n        return field\n\n    @classmethod\n    def fitness(cls, start_field, end_field, delta):\n        \"\"\"\n        Calculate fitness for particular candidate (start configuration of the field)\n        :param start_field: candidate (start configuration)\n        :param end_field: target (stop configuration)\n        :param delta: number of steps to proceed before comparing to stop configuration\n        :return: value in range [0, 1] that indicates fractions of cells that match their state\n        \"\"\"\n        candidate = make_move(start_field, moves=delta)\n        return (candidate == end_field).sum() / 400\n\n      \n    @classmethod\n    def score_population(cls, population, Y, delta):\n        \"\"\"\n        Apply fitness function for each gene in a population\n        :param population: list of candidate solutions\n        :param Y: 20x20 array that represents field in stopping condition\n        :param delta: number of steps to revert\n        :return: list of scores for each solution\n        \"\"\"\n        return [cls.fitness(gene, Y, delta) for gene in population]\n\n    def parallel_score_population(self, population, Y, delta):\n        \"\"\"\n        Apply fitness function for each gene in a population in parallel\n        :param population: list of candidate solutions\n        :param Y: 20x20 array that represents field in stopping condition\n        :param delta: number of steps to revert\n        :return: list of scores for each solution\n        \"\"\"\n        return self.pool.map(partial(parallel_fitness, Y=Y, delta=delta), population)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8f477caa8c253e7ee38e14d2223992d08952b58"},"cell_type":"code","source":"import multiprocessing as mp\nimport scipy\n\n\ndef work(solver, Y, delta):\n    # this is required for every worker to have different initial seed. Otherwise they inherit it from this thread\n    scipy.random.seed()\n    return solver.solve(Y, delta)\n\n\nclass MPGeneticSolver:\n    def __init__(self, n_proc='auto', *args, **kwargs):\n        \"\"\"\n        Multi-process version of Genetic Solver with different initial conditions\n        :param n_proc: number of processes to create\n        :param args: GeneticSolver arguments (see its documentation for more)\n        :param kwargs: GeneticSolver key-value arguments\n        \"\"\"\n        if n_proc == 'auto':\n            n_proc = mp.cpu_count()\n        self.n_proc = n_proc\n        self.pool = mp.Pool(mp.cpu_count() if n_proc == 'auto' else n_proc)\n        self.args = args\n        self.kwargs = kwargs\n        self._solvers = None\n        if 'fitness_parallel' in self.args or ('fitness_parallel' in self.kwargs and self.kwargs['fitness_parallel']):\n            raise ValueError(\"Fitness function cannot be parallelized in MPGeneticSolver\")\n\n    def solve(self, Y, delta, return_all=True):\n        \"\"\"\n        Solve RGoL problem\n        :param Y: 20x20 array that represents field in stopping condition\n        :param delta: number of steps to revert\n        :param return_all: if True, returns all of the results from different runners, as well as their scores.\n                           If False only solution associated with the best score is returned\n        :return: either list of (solution, score) pairs or the best solution (see `return_all`)\n        \"\"\"\n        self._solvers = [GeneticSolver(*self.args, **self.kwargs) for _ in range(self.n_proc)]\n        tasks = [(solver, Y, delta) for solver in self._solvers]\n        results = self.pool.starmap(work, tasks)\n        return results if return_all else self.select_best(results)\n\n    @classmethod\n    def select_best(cls, solutions):\n        \"\"\"\n        Using output of solve method, select the best solution\n        :param solutions: list of (solution, score) pairs\n        :return: 20x20 array that represents the solution (starting board condition)\n        \"\"\"\n        return sorted(solutions, key=lambda x:x[1], reverse=True)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"013227f34f237a3ccb50f0c744600a8e1553df14"},"cell_type":"code","source":"class SolutionRunner:\n  def __init__(self, save_fname='solution.csv', verbosity=0):\n    self.save_fname = save_fname\n    self.verbosity = verbosity\n    self.log = []\n    self.running_avg = 0\n    self.n = 0\n  \n  \n  def solve_df(self, df, first_n=None, save_to=None):\n    solver = MPGeneticSolver(early_stopping=False)\n    \n    solution_df = pd.DataFrame([], columns=['id', 'score'] + ['start.'+ str(_) for _ in range(1, 401)], dtype=int)\n    for col in solution_df.columns:\n      solution_df[col] = solution_df[col].astype(np.int32)\n    \n    self.running_avg = 0\n    self.n = 0\n    self.log = []\n    best, worst = None, None\n    for i, (id, (idx, row)) in enumerate(zip(df.index, df.iterrows())):\n        delta, Y = row.values[0], row.values[1:].reshape((20, 20)).astype('uint8')\n        solution = solver.solve(Y, delta, return_all=False)\n\n        board, score = solution\n        flat_board = np.insert(board.ravel(), 0, id)\n        flat_board = np.insert(flat_board, 1, int(score * 100))\n        solution_df = solution_df.append(pd.Series(flat_board, index=solution_df.columns), ignore_index=True)\n\n        self.log.append((idx, score))\n        if best is None or best[1] < score:\n            best = (idx, score)\n        if worst is None or worst[1] > score:\n            worst = (idx, score)\n        self.n += 1\n        self.running_avg = (self.running_avg * (self.n - 1) + score) / self.n\n        if self.verbosity:\n          print(f\"{idx} is solved with score {score}. Average score: {self.running_avg}\")\n        if first_n and i >= first_n:\n          break\n    if self.verbosity:\n      print(\"Best score:\", best)\n      print(\"Worst score:\", worst)\n    if save_to is not None:\n      solution_df.to_csv(save_to, index=False)\n    else:\n      solution_df.to_csv(self.save_fname, index=False)\n    return solution_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4b6809d82936d83b76bcd0e80c527b03f23a2f1"},"cell_type":"code","source":"sr = SolutionRunner(verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbb7fd30a861ce26ab8625da591825798a9e616e"},"cell_type":"code","source":"solution = sr.solve_df(df, 300, 's401-700.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5356e2efdd6c1ce37f01829b36aa456e7d39b765"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}